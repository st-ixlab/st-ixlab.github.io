<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://st-ixlab.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://st-ixlab.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2026-01-04T05:50:59+00:00</updated><id>https://st-ixlab.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">ğŸ“„ One paper **accepted** to **UIST** 2025 **Poster** track!</title><link href="https://st-ixlab.github.io/blog/2025/one-paper-accepted-to-uist-2025-poster-track/" rel="alternate" type="text/html" title="ğŸ“„ One paper **accepted** to **UIST** 2025 **Poster** track!"/><published>2025-08-05T00:00:00+00:00</published><updated>2025-08-05T00:00:00+00:00</updated><id>https://st-ixlab.github.io/blog/2025/one-paper-accepted-to-uist-2025-poster-track</id><content type="html" xml:base="https://st-ixlab.github.io/blog/2025/one-paper-accepted-to-uist-2025-poster-track/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/news-20250805-1-480.webp 480w,/assets/img/news-20250805-1-800.webp 800w,/assets/img/news-20250805-1-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/news-20250805-1.png" class="rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Our paper â€œSilent Yet Expressive: Toward Seamless VR Communication through Emotion-aware Silent Speech Interfacesâ€ by Yewon Min, Jiyeon Oh, Jae-Yeop Jeong was accepted to 2025 UIST Poster tracK!</p>]]></content><author><name></name></author><category term="news"/><category term="news"/><summary type="html"><![CDATA[One paper accepted to UIST 2025 Poster track!]]></summary></entry><entry><title type="html">ğŸ† Received **Best Paper** **Award** for **IUI**2025 paper!</title><link href="https://st-ixlab.github.io/blog/2025/received-best-paper-award-for-iui2025-paper/" rel="alternate" type="text/html" title="ğŸ† Received **Best Paper** **Award** for **IUI**2025 paper!"/><published>2025-04-18T00:00:00+00:00</published><updated>2025-04-18T00:00:00+00:00</updated><id>https://st-ixlab.github.io/blog/2025/received-best-paper-award-for-iui2025-paper</id><content type="html" xml:base="https://st-ixlab.github.io/blog/2025/received-best-paper-award-for-iui2025-paper/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/news-2025-04-18-1-480.webp 480w,/assets/img/news-2025-04-18-1-800.webp 800w,/assets/img/news-2025-04-18-1-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/news-2025-04-18-1.png" class="rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Our paper â€œA picture is worth a thousand words? Investigating the Impact of Image Aids in AR on Memory Recall for Everyday Tasksâ€ byÂ Elizaveta Lukianova and Jae-Yeop Jeong received â€œBest Paper Awardâ€ from IUI 2025!</p>]]></content><author><name></name></author><category term="news"/><category term="news"/><summary type="html"><![CDATA[Received Best Paper Award for IUI2025 paper!]]></summary></entry><entry><title type="html">ğŸ† Received **Best Paper** **Honorable Mention** for **CHI**2025 paper!</title><link href="https://st-ixlab.github.io/blog/2025/received-best-paper-honorable-mention-for-chi2025-paper/" rel="alternate" type="text/html" title="ğŸ† Received **Best Paper** **Honorable Mention** for **CHI**2025 paper!"/><published>2025-04-18T00:00:00+00:00</published><updated>2025-04-18T00:00:00+00:00</updated><id>https://st-ixlab.github.io/blog/2025/received-best-paper-honorable-mention-for-chi2025-paper</id><content type="html" xml:base="https://st-ixlab.github.io/blog/2025/received-best-paper-honorable-mention-for-chi2025-paper/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/chihonor-480.webp 480w,/assets/img/chihonor-800.webp 800w,/assets/img/chihonor-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/chihonor.png" class="rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Our paper â€œUnderstanding User Behavior in Window Selection using Dragging for Multiple Targetsâ€Â  byÂ Jae-Yeop Jeong received â€œBest Paper Honorable Mentionâ€ from CHI 2025!</p>]]></content><author><name></name></author><category term="news"/><category term="news"/><summary type="html"><![CDATA[Received Best Paper Honorable Mention for CHI2025 paper!]]></summary></entry><entry><title type="html">ğŸ“„ One paper **accepted** to 2025 **CHI** **LBW**!</title><link href="https://st-ixlab.github.io/blog/2025/one-paper-accepted-to-2025-chi-lbw/" rel="alternate" type="text/html" title="ğŸ“„ One paper **accepted** to 2025 **CHI** **LBW**!"/><published>2025-02-24T00:00:00+00:00</published><updated>2025-02-24T00:00:00+00:00</updated><id>https://st-ixlab.github.io/blog/2025/one-paper-accepted-to-2025-chi-lbw</id><content type="html" xml:base="https://st-ixlab.github.io/blog/2025/one-paper-accepted-to-2025-chi-lbw/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/news-2025-02-24-1-480.webp 480w,/assets/img/news-2025-02-24-1-800.webp 800w,/assets/img/news-2025-02-24-1-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/news-2025-02-24-1.png" class="rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Our paper â€œExploring Emotion Expression Through Silent Speech Interface in Public VR/MR: Effects of Automation on User Experienceâ€ by Yewon Min, Jiyeon Oh, Jae-Yeop Jeong was accepted to 2025 CHI LBW tracK!</p>]]></content><author><name></name></author><category term="news"/><category term="news"/><summary type="html"><![CDATA[One paper accepted to 2025 CHI LBW!]]></summary></entry><entry><title type="html">ğŸ“„ One paper **accepted** to **ACM** **IUI** 2025!</title><link href="https://st-ixlab.github.io/blog/2025/one-paper-accepted-to-acm-iui-2025/" rel="alternate" type="text/html" title="ğŸ“„ One paper **accepted** to **ACM** **IUI** 2025!"/><published>2025-02-03T00:00:00+00:00</published><updated>2025-02-03T00:00:00+00:00</updated><id>https://st-ixlab.github.io/blog/2025/one-paper-accepted-to-acm-iui-2025</id><content type="html" xml:base="https://st-ixlab.github.io/blog/2025/one-paper-accepted-to-acm-iui-2025/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/news-2025-02-03-1-480.webp 480w,/assets/img/news-2025-02-03-1-800.webp 800w,/assets/img/news-2025-02-03-1-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/news-2025-02-03-1.png" class="rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Our paperÂ â€œA picture is worth a thousand words? Investigating the Impact of Image Aids in AR on Memory Recall for Everyday Tasksâ€ by Elizaveta Lukianova and Jae-Yeop jeong was accepted to ACM IUI 2025 as Full Paper!</p>]]></content><author><name></name></author><category term="news"/><category term="news"/><summary type="html"><![CDATA[One paper accepted to ACM IUI 2025!]]></summary></entry><entry><title type="html">ğŸ“„ Two papers **accepted** to **ACM** **CHI** 2025!</title><link href="https://st-ixlab.github.io/blog/2025/two-papers-accepted-to-acm-chi-2025/" rel="alternate" type="text/html" title="ğŸ“„ Two papers **accepted** to **ACM** **CHI** 2025!"/><published>2025-02-03T00:00:00+00:00</published><updated>2025-02-03T00:00:00+00:00</updated><id>https://st-ixlab.github.io/blog/2025/two-papers-accepted-to-acm-chi-2025</id><content type="html" xml:base="https://st-ixlab.github.io/blog/2025/two-papers-accepted-to-acm-chi-2025/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/news-20250203-1-480.webp 480w,/assets/img/news-20250203-1-800.webp 800w,/assets/img/news-20250203-1-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/news-20250203-1.png" class="rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Our papers were accepted to ACM CHI 2025 as Full Papers! -Â â€Through the Looking Glass, and What We Found Thereâ€: A Comprehensive Study of User Experiences with Pass-Through Devices in Everyday Activitiesâ€ by Daewook Kim, Yewon Min, Jae-Yeop Jeong, Sehee Han, JiYeon Hwang -Â â€œUnderstanding User Behavior in Window Selection using Dragging for Multiple Targetsâ€ by Jae-Yeop Jeong</p>]]></content><author><name></name></author><category term="news"/><category term="news"/><summary type="html"><![CDATA[Two papers accepted to ACM CHI 2025!]]></summary></entry><entry><title type="html">ğŸ“„ One paper **accepted** to **SIGGRAPH** ASIA 2024 as **poster**!</title><link href="https://st-ixlab.github.io/blog/2024/one-paper-accepted-to-siggraph-asia-2024-as-poster/" rel="alternate" type="text/html" title="ğŸ“„ One paper **accepted** to **SIGGRAPH** ASIA 2024 as **poster**!"/><published>2024-10-01T00:00:00+00:00</published><updated>2024-10-01T00:00:00+00:00</updated><id>https://st-ixlab.github.io/blog/2024/one-paper-accepted-to-siggraph-asia-2024-as-poster</id><content type="html" xml:base="https://st-ixlab.github.io/blog/2024/one-paper-accepted-to-siggraph-asia-2024-as-poster/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/news-2024-10-01-1-480.webp 480w,/assets/img/news-2024-10-01-1-800.webp 800w,/assets/img/news-2024-10-01-1-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/news-2024-10-01-1.jpg" class="rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Our paper â€œDesigning LLM Response Layouts for XR Workspaces in Vehiclesâ€ was accepted to ISMAR 2024 as Poster!</p>]]></content><author><name></name></author><category term="news"/><category term="news"/><summary type="html"><![CDATA[One paper accepted to SIGGRAPH ASIA 2024 as poster!]]></summary></entry><entry><title type="html">ğŸ“„ One paper **accepted** to **ISMAR** 2024!</title><link href="https://st-ixlab.github.io/blog/2024/one-paper-accepted-to-ismar-2024/" rel="alternate" type="text/html" title="ğŸ“„ One paper **accepted** to **ISMAR** 2024!"/><published>2024-08-02T00:00:00+00:00</published><updated>2024-08-02T00:00:00+00:00</updated><id>https://st-ixlab.github.io/blog/2024/one-paper-accepted-to-ismar-2024</id><content type="html" xml:base="https://st-ixlab.github.io/blog/2024/one-paper-accepted-to-ismar-2024/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/news-2024-08-02-1-480.webp 480w,/assets/img/news-2024-08-02-1-800.webp 800w,/assets/img/news-2024-08-02-1-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/news-2024-08-02-1.png" class="rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Our paper â€œPublic Speaking Q&amp;A Practice with LLM-Generated Personas in Virtual Realityâ€ was accepted to ISMAR 2024 as Poster!</p>]]></content><author><name></name></author><category term="news"/><category term="news"/><summary type="html"><![CDATA[One paper accepted to ISMAR 2024!]]></summary></entry><entry><title type="html">ğŸ“„ Our paper **accepted** to EAIT! (IF:5.5, 6.9%)</title><link href="https://st-ixlab.github.io/blog/2024/our-paper-accepted-to-eait-if-55-69/" rel="alternate" type="text/html" title="ğŸ“„ Our paper **accepted** to EAIT! (IF:5.5, 6.9%)"/><published>2024-04-30T00:00:00+00:00</published><updated>2024-04-30T00:00:00+00:00</updated><id>https://st-ixlab.github.io/blog/2024/our-paper-accepted-to-eait-if-55-69</id><content type="html" xml:base="https://st-ixlab.github.io/blog/2024/our-paper-accepted-to-eait-if-55-69/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/10639_Cover_153w-480.webp 480w,/assets/img/10639_Cover_153w-800.webp 800w,/assets/img/10639_Cover_153w-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/10639_Cover_153w.jpg" class="rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Our paper â€œEnhancing Learner Experience with Instructor Cues in Video Lectures: A Comprehensive Exploration and Design Discovery toward A Novel Gaze Visualizationâ€ has been accepted to Education and Information Technologies (SCI, IF:5.5 (6.9%)) Congratulations to the authors!</p>]]></content><author><name></name></author><category term="news"/><category term="news"/><summary type="html"><![CDATA[Our paper accepted to EAIT! (IF:5.5, 6.9%)]]></summary></entry><entry><title type="html">ğŸ“„ Our paper **accepted** to IJHCI! (IF:4.7, 21.9%)</title><link href="https://st-ixlab.github.io/blog/2024/our-paper-accepted-to-ijhci-if47-219/" rel="alternate" type="text/html" title="ğŸ“„ Our paper **accepted** to IJHCI! (IF:4.7, 21.9%)"/><published>2024-04-30T00:00:00+00:00</published><updated>2024-04-30T00:00:00+00:00</updated><id>https://st-ixlab.github.io/blog/2024/our-paper-accepted-to-ijhci-if47-219</id><content type="html" xml:base="https://st-ixlab.github.io/blog/2024/our-paper-accepted-to-ijhci-if47-219/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/news-2024-04-30-1-480.webp 480w,/assets/img/news-2024-04-30-1-800.webp 800w,/assets/img/news-2024-04-30-1-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/news-2024-04-30-1.jpg" class="rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Our paper â€œEchoTap: Non-verbal Sound Interaction with Knock and Tap Gesturesâ€ has been accepted to International Journal of Human-Computer Interaction (SCI, IF:4.7 (21.9%)) Congratulations to the authors!</p>]]></content><author><name></name></author><category term="news"/><category term="news"/><summary type="html"><![CDATA[Our paper accepted to IJHCI! (IF:4.7, 21.9%)]]></summary></entry></feed>